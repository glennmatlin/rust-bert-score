#!/usr/bin/env python3
"""
Generate Rust baseline data module from extracted baseline JSON.
Creates a comprehensive baseline_data.rs file with all values.
"""

import json
import os
from pathlib import Path

def rust_float(value):
    """Format float for Rust code."""
    return f"{value:.8}f32"

def rust_model_name(model_name):
    """Convert model name to valid Rust identifier."""
    # Replace special characters with underscores
    name = model_name.replace("/", "_")
    name = name.replace("-", "_")
    name = name.upper()
    return name

def generate_rust_code(baselines):
    """Generate Rust code from baseline data."""
    lines = []
    
    # Header
    lines.extend([
        "//! Baseline rescaling data extracted from Python bert_score package.",
        "//! This file is auto-generated by scripts/generate_baseline_data.py",
        "//! DO NOT EDIT MANUALLY",
        "",
        "use std::collections::HashMap;",
        "use once_cell::sync::Lazy;",
        "",
        "#[derive(Debug, Clone, Copy)]",
        "pub struct LayerBaseline {",
        "    pub layer: usize,",
        "    pub precision: f32,",
        "    pub recall: f32,",
        "    pub f1: f32,",
        "}",
        "",
        "/// All baseline data indexed by (language, model_name)",
        "pub static BASELINE_DATA: Lazy<HashMap<(&'static str, &'static str), Vec<LayerBaseline>>> = Lazy::new(|| {",
        "    let mut map = HashMap::new();",
        ""
    ])
    
    # Generate data for each language and model
    for lang in sorted(baselines.keys()):
        lines.append(f"    // Language: {lang}")
        
        for model in sorted(baselines[lang].keys()):
            layer_data = baselines[lang][model]
            
            lines.append(f"    map.insert((\"{lang}\", \"{model}\"), vec![")
            
            for layer in layer_data:
                lines.append(f"        LayerBaseline {{ layer: {layer['layer']}, "
                           f"precision: {rust_float(layer['precision'])}, "
                           f"recall: {rust_float(layer['recall'])}, "
                           f"f1: {rust_float(layer['f1'])} }},")
            
            lines.append("    ]);")
        
        lines.append("")
    
    lines.extend([
        "    map",
        "});",
        "",
        "/// Get baseline scores for a specific model, language, and layer.",
        "pub fn get_baseline(model_name: &str, language: &str, layer: usize) -> Option<(f32, f32, f32)> {",
        "    BASELINE_DATA",
        "        .get(&(language, model_name))",
        "        .and_then(|layers| {",
        "            layers",
        "                .iter()",
        "                .find(|l| l.layer == layer)",
        "                .map(|l| (l.precision, l.recall, l.f1))",
        "        })",
        "}",
        "",
        "/// Get all available languages.",
        "pub fn get_languages() -> Vec<&'static str> {",
        "    let mut langs: Vec<_> = BASELINE_DATA",
        "        .keys()",
        "        .map(|(lang, _)| *lang)",
        "        .collect::<std::collections::HashSet<_>>()",
        "        .into_iter()",
        "        .collect();",
        "    langs.sort();",
        "    langs",
        "}",
        "",
        "/// Get all available models for a language.",
        "pub fn get_models_for_language(language: &str) -> Vec<&'static str> {",
        "    let mut models: Vec<_> = BASELINE_DATA",
        "        .keys()",
        "        .filter(|(lang, _)| *lang == language)",
        "        .map(|(_, model)| *model)",
        "        .collect();",
        "    models.sort();",
        "    models",
        "}",
        "",
        "#[cfg(test)]",
        "mod tests {",
        "    use super::*;",
        "",
        "    #[test]",
        "    fn test_roberta_large_baseline() {",
        "        // Test the specific case we've been validating",
        "        let baseline = get_baseline(\"roberta-large\", \"en\", 17);",
        "        assert!(baseline.is_some());",
        "        let (p, r, f1) = baseline.unwrap();",
        "        assert!((p - 0.83150584).abs() < 1e-6);",
        "        assert!((r - 0.8314941).abs() < 1e-6);",
        "        assert!((f1 - 0.83122575).abs() < 1e-6);",
        "    }",
        "",
        "    #[test]",
        "    fn test_languages() {",
        "        let langs = get_languages();",
        "        assert!(langs.contains(&\"en\"));",
        "        assert!(langs.contains(&\"zh\"));",
        "        assert!(langs.len() >= 12);",
        "    }",
        "",
        "    #[test]",
        "    fn test_models_for_language() {",
        "        let en_models = get_models_for_language(\"en\");",
        "        assert!(en_models.contains(&\"roberta-large\"));",
        "        assert!(en_models.contains(&\"bert-base-uncased\"));",
        "        assert!(en_models.len() >= 30);",
        "    }",
        "}",
    ])
    
    return "\n".join(lines)

def main():
    """Generate Rust baseline data module."""
    print("üîß Generating Rust Baseline Data Module")
    print("="*60)
    
    # Load baseline data
    baseline_file = "data/baselines.json"
    if not os.path.exists(baseline_file):
        print(f"Error: {baseline_file} not found. Run extract_baselines.py first.")
        return 1
    
    with open(baseline_file, "r") as f:
        baselines = json.load(f)
    
    # Generate Rust code
    rust_code = generate_rust_code(baselines)
    
    # Save to file
    output_file = "src/core/baseline_data.rs"
    with open(output_file, "w") as f:
        f.write(rust_code)
    
    print(f"‚úì Generated {output_file}")
    print(f"  Total lines: {len(rust_code.splitlines())}")
    
    # Update Cargo.toml to include once_cell dependency if needed
    print("\n‚ö†Ô∏è  Make sure to add 'once_cell' to Cargo.toml dependencies:")
    print('    once_cell = "1.19"')
    
    # Generate summary
    total_baselines = sum(len(models) for models in baselines.values() for models in models.values())
    print(f"\n‚úì Generated baseline data for:")
    print(f"  - {len(baselines)} languages")
    print(f"  - {sum(len(models) for models in baselines.values())} model configurations")
    print(f"  - {total_baselines} total baseline entries")

if __name__ == "__main__":
    main()